{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Based Training of WANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from functools import reduce, partial\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiActivationModule(torch.nn.Module):\n",
    "    \"\"\"Applies multiple elementwise activation functions to a tensor.\"\"\"\n",
    "    \n",
    "    discretized = False\n",
    "    \n",
    "    available_act_functions = [\n",
    "        ('relu', torch.relu),\n",
    "        ('sigmoid', torch.sigmoid),\n",
    "        ('tanh', torch.tanh),\n",
    "        ('gaussian (standard)', lambda x: torch.exp(-torch.square(x) / 2.0)),\n",
    "        ('step', lambda t: (t > 0.0) * 1.0),\n",
    "        ('identity', lambda x: x),\n",
    "        ('inverse', torch.neg),\n",
    "        ('squared', torch.square),\n",
    "        ('abs', torch.abs),\n",
    "        ('cos', torch.cos),\n",
    "        ('sin', torch.sin),\n",
    "    ]\n",
    "    \n",
    "    @property\n",
    "    def n_funcs(self):\n",
    "        return len(self.funcs)\n",
    "    \n",
    "    def __init__(self, n_out):\n",
    "        super().__init__()\n",
    "        self.funcs = [f[1] for f in self.available_act_functions]\n",
    "        \n",
    "        self.weight = torch.nn.Parameter(torch.zeros((self.n_funcs, n_out)))\n",
    "        self.frozen = torch.zeros(n_out, dtype=bool)\n",
    "        self.soft = torch.nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        coefficients = self.soft(self.weight)\n",
    "        \n",
    "        return reduce(\n",
    "            lambda first, act: (\n",
    "                torch.add(\n",
    "                    first,\n",
    "                    torch.mul(\n",
    "                        act[1](x),  # apply activation func\n",
    "                        coefficients[act[0], :])\n",
    "            )),\n",
    "            enumerate(self.funcs),  # index, func\n",
    "            torch.zeros_like(x)  # start value\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestrictedLinear(torch.nn.Module):\n",
    "    \"\"\"Similar to torch.nn.Linear, but restricts weights between -1 and 1.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()     \n",
    "        self.sign = torch.nn.Softsign()\n",
    "        self.weight = torch.nn.Parameter(torch.empty(n_in, n_out))\n",
    "        self.frozen = torch.zeros(*self.weight.size(), dtype=bool)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weight = torch.where(self.frozen, self.weight, self.sign(self.weight))\n",
    "        return torch.nn.functional.linear(x, weight.T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLayer(torch.nn.Module):\n",
    "    \"\"\"Contatenates output of the active nodes and prior nodes.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, n_out, shared_weight):\n",
    "        super().__init__()\n",
    "        self.linear = RestrictedLinear(n_in, n_out)\n",
    "        self.activation = MultiActivationModule(n_out)\n",
    "        \n",
    "        self.shared_weight = shared_weight\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear = self.linear(x) * self.shared_weight[:, None, None]\n",
    "        \n",
    "        inner_out = self.activation(linear)\n",
    "        \n",
    "        return torch.cat([x, inner_out], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, RestrictedLinear):\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "    elif isinstance(m, MultiActivationModule):\n",
    "        torch.nn.init.normal_(m.weight.data)\n",
    "               \n",
    "def reset_masked_gradients(m):\n",
    "    # set gradient of masked parameters to 0 -> these parameters won't be updated by the optimizer\n",
    "    if isinstance(m, MultiActivationModule):\n",
    "        m.weight.grad[:, m.frozen] = 0.0\n",
    "    if isinstance(m, RestrictedLinear):\n",
    "        m.weight.grad[m.frozen] = 0.0\n",
    "        \n",
    "def freeze_some_act_funcs(m, ratio=0.2):\n",
    "    if isinstance(m, MultiActivationModule):\n",
    "        indices = torch.max(m.weight, 0).indices\n",
    "        \n",
    "        to_freeze = (torch.rand(*m.frozen.size()) <= ratio) & ~m.frozen\n",
    "        \n",
    "        if torch.any(to_freeze):\n",
    "            indices = torch.max(m.weight[:, to_freeze], 0).indices\n",
    "            m.weight.data[:, to_freeze] = torch.nn.functional.one_hot(indices, m.n_funcs).T.float()\n",
    "            m.frozen[to_freeze] = True\n",
    "        \n",
    "def freeze_some_weights(m, ratio=0.2, zero_ratio=0.4):\n",
    "    if isinstance(m, RestrictedLinear):       \n",
    "        # mask-0 operation\n",
    "        if torch.any(~m.frozen):\n",
    "            alpha_zero = np.percentile(m.weight.data[~m.frozen].abs(), 100 * ratio * zero_ratio)\n",
    "            mask_zero = (m.weight.data.abs() <= alpha_zero) & ~m.frozen\n",
    "\n",
    "            # mask-1 operation\n",
    "            alpha_one = np.percentile(-m.weight.data[~m.frozen].abs(), 100 * ratio * (1-zero_ratio))\n",
    "            mask_one = (-m.weight.data.abs() <= alpha_one) & ~m.frozen\n",
    "        \n",
    "            m.frozen[mask_zero] = True\n",
    "            m.frozen[mask_one] = True\n",
    "\n",
    "            m.weight.data[mask_zero] = 0.0\n",
    "            m.weight.data[mask_one] = m.weight.data[mask_one].sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "#train_X, test_X, train_y, test_y = train_test_split(dataset['data'],\n",
    "#                                                    dataset['target'], test_size=0.2)\n",
    "\n",
    "\n",
    "# Just going for fitting here. (Todo: Change stuff in paper for usefull comparison)\n",
    "train_X = dataset['data']\n",
    "train_y = dataset['target']\n",
    "test_X = train_X\n",
    "test_y = train_y\n",
    "\n",
    "train_X = np.hstack([train_X, np.ones((train_X.shape[0], 1))])\n",
    "test_X = np.hstack([test_X, np.ones((test_X.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap up with Variable in pytorch\n",
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, *layer_sizes):\n",
    "        shared_weight = Variable(torch.Tensor([1]))\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = list()\n",
    "        \n",
    "        n_in = layer_sizes[0]\n",
    "        \n",
    "        for n_out in layer_sizes[1:]:\n",
    "            layers.append(ConcatLayer(n_in, n_out, shared_weight))\n",
    "            n_in += n_out\n",
    "        \n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        net_out = self.network(x)\n",
    "        net_out = net_out[..., -3:]\n",
    "        return self.softmax(net_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "def train(model, n_epochs=2000):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = train_X.unsqueeze(dim=0)\n",
    "        out = model(batch).view(-1, 3)\n",
    "        loss = criterion(out, train_y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # set masked gradients to zero, so the weights will not be updated\n",
    "        model.apply(reset_masked_gradients)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print ('number of epoch', epoch, 'loss', loss.data)\n",
    "\n",
    "def evaluate(model):\n",
    "    predict_out = model(test_X.unsqueeze(dim=0)).view(-1, 3)\n",
    "    _, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "    print ('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "\n",
    "#    print ('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "#    print ('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "#    print ('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "#    print ('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss tensor(1.1104)\n",
      "number of epoch 100 loss tensor(1.0213)\n",
      "number of epoch 200 loss tensor(0.9851)\n",
      "number of epoch 300 loss tensor(0.9474)\n",
      "number of epoch 400 loss tensor(0.8961)\n",
      "number of epoch 500 loss tensor(0.8268)\n",
      "number of epoch 600 loss tensor(0.7644)\n",
      "number of epoch 700 loss tensor(0.7366)\n",
      "number of epoch 800 loss tensor(0.7192)\n",
      "number of epoch 900 loss tensor(0.7023)\n",
      "prediction accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "model = Model(5,2,2,3)\n",
    "model.apply(weight_init)\n",
    "train(model, 1000)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss tensor(0.6604)\n",
      "--- Iteration 0 ---\n",
      "prediction accuracy 0.98\n",
      "number of epoch 0 loss tensor(0.6103)\n",
      "number of epoch 0 loss tensor(0.5796)\n",
      "number of epoch 0 loss tensor(0.6108)\n",
      "number of epoch 0 loss tensor(0.5776)\n",
      "--- Iteration 4 ---\n",
      "prediction accuracy 0.9866666666666667\n",
      "number of epoch 0 loss tensor(0.5701)\n",
      "number of epoch 0 loss tensor(0.5684)\n",
      "number of epoch 0 loss tensor(0.5667)\n",
      "number of epoch 0 loss tensor(0.5645)\n",
      "--- Iteration 8 ---\n",
      "prediction accuracy 0.9933333333333333\n",
      "number of epoch 0 loss tensor(0.8847)\n",
      "number of epoch 0 loss tensor(0.5706)\n",
      "number of epoch 0 loss tensor(0.5683)\n",
      "number of epoch 0 loss tensor(0.5666)\n",
      "--- Iteration 12 ---\n",
      "prediction accuracy 0.9933333333333333\n",
      "number of epoch 0 loss tensor(0.5654)\n",
      "number of epoch 0 loss tensor(0.5644)\n",
      "number of epoch 0 loss tensor(0.8510)\n",
      "number of epoch 0 loss tensor(0.5697)\n",
      "--- Iteration 16 ---\n",
      "prediction accuracy 0.9933333333333333\n",
      "number of epoch 0 loss tensor(0.5671)\n",
      "number of epoch 0 loss tensor(0.5655)\n",
      "number of epoch 0 loss tensor(0.5648)\n",
      "=== Final ===\n",
      "prediction accuracy 0.41333333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    model.apply(partial(freeze_some_act_funcs, ratio=0.1))\n",
    "    train(model, 100)\n",
    "    if i % 4 == 0:\n",
    "        print (f\"--- Iteration {i} ---\")\n",
    "        evaluate(model)\n",
    "    \n",
    "print (\"=== Final ===\")\n",
    "model.apply(partial(freeze_some_act_funcs, ratio=1))\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss tensor(1.1854)\n",
      "--- Iteration 0 ---\n",
      "prediction accuracy 0.48\n",
      "number of epoch 0 loss tensor(0.6064)\n",
      "number of epoch 0 loss tensor(0.9192)\n",
      "number of epoch 0 loss tensor(1.2106)\n",
      "number of epoch 0 loss tensor(0.9370)\n",
      "--- Iteration 4 ---\n",
      "prediction accuracy 0.6333333333333333\n",
      "number of epoch 0 loss tensor(0.8860)\n",
      "number of epoch 0 loss tensor(0.8859)\n",
      "number of epoch 0 loss tensor(0.8851)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "--- Iteration 8 ---\n",
      "prediction accuracy 0.6666666666666666\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "--- Iteration 12 ---\n",
      "prediction accuracy 0.6666666666666666\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "--- Iteration 16 ---\n",
      "prediction accuracy 0.6666666666666666\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "number of epoch 0 loss tensor(0.8848)\n",
      "=== Final ===\n",
      "prediction accuracy 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.apply(partial(freeze_some_weights, ratio=1/(epochs-i)))\n",
    "    train(model, 50)\n",
    "    if i % 4 == 0:\n",
    "        print (f\"--- Iteration {i} ---\")\n",
    "        evaluate(model)\n",
    "\n",
    "print(\"=== Final ===\")\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1., -1., -1.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 1., -1.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 1., -1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 1.,  0., -1.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.network[2].linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
